"""
Routes API pour le traitement audio et g√©n√©ration d'insights
"""
import logging
import numpy as np
from datetime import datetime
from fastapi import APIRouter, Request, HTTPException

from services import TranscriptionService, CoachingService
from services.relevance_filter import RelevanceFilter
from api.calls import get_active_calls
from config.settings import (
    TIME_THRESHOLD_DUPLICATE,
    COOLDOWN_BASE,
    COOLDOWN_HIGH_RELEVANCE,
    COOLDOWN_AFTER_INSIGHT,
    MIN_RELEVANCE_SCORE,
    ALLOW_COOLDOWN_BYPASS
)

logger = logging.getLogger(__name__)

router = APIRouter(tags=["audio"])

# Services
transcription_service = TranscriptionService()
coaching_service = CoachingService()
relevance_filter = RelevanceFilter()


@router.post("/audio/{session_id}")
async def process_audio(session_id: str, request: Request):
    """
    Traite l'audio client et commercial, g√©n√®re des insights
    Version optimis√©e avec contexte structur√© enrichi
    """
    
    active_calls = get_active_calls()
    
    if session_id not in active_calls:
        raise HTTPException(status_code=404, detail="Session non trouv√©e")
    
    manager = active_calls[session_id]
    
    # R√©cup√©rer les fichiers audio
    form = await request.form()
    client_audio_file = form.get('client_audio')
    commercial_audio_file = form.get('commercial_audio')
    
    if not client_audio_file or not commercial_audio_file:
        raise HTTPException(status_code=400, detail="Les deux fichiers audio sont requis")
    
    # Lire les donn√©es audio
    client_data = await client_audio_file.read()
    commercial_data = await commercial_audio_file.read()
    
    client_audio = np.frombuffer(client_data, dtype=np.int16)
    commercial_audio = np.frombuffer(commercial_data, dtype=np.int16)
    
    # TRANSCRIPTION PARALL√àLE
    client_text, commercial_text = await transcription_service.transcribe_parallel(
        client_audio,
        commercial_audio
    )
    
    # Ajouter au contexte (üÜï avec await pour d√©tection phase IA)
    if client_text:
        await manager.add_message("assistant", client_text)

    if commercial_text:
        await manager.add_message("user", commercial_text)

    # Log historique
    if client_text or commercial_text:
        manager.log_conversation_history()

    # Si aucun des deux n'a parl√©
    if not client_text and not commercial_text:
        return {"advice": None, "transcription": ""}

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üÜï SYST√àME DE PERTINENCE INTELLIGENTE v2
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # 1. V√©rifier le score de pertinence AVANT de g√©n√©rer l'insight
    should_generate, relevance_score, analysis = relevance_filter.should_generate_insight(
        manager.messages,
        manager.pillar_progress,
        manager.last_insight_time,
        manager.conversation_phase,
        min_score=MIN_RELEVANCE_SCORE
    )

    # 2. Cooldown adaptatif
    current_time = datetime.now().timestamp()
    elapsed_since_last = current_time - manager.last_insight_time if manager.last_insight_time > 0 else 999

    # D√©terminer le cooldown requis selon le score
    if relevance_score >= 85:
        required_cooldown = COOLDOWN_HIGH_RELEVANCE  # 10s pour √©v√©nements critiques
    elif relevance_score >= 70:
        required_cooldown = COOLDOWN_BASE  # 20s pour pertinence moyenne
    else:
        required_cooldown = COOLDOWN_AFTER_INSIGHT  # 25s pour faible pertinence

    # V√©rifier le cooldown (sauf bypass autoris√©)
    cooldown_active = elapsed_since_last < required_cooldown
    can_bypass = ALLOW_COOLDOWN_BYPASS and relevance_score >= 85

    if cooldown_active and not can_bypass:
        logger.info(f"\n{'='*80}")
        logger.info(f"[COOLDOWN] ‚è∏Ô∏è  INSIGHT BLOQU√â - COOLDOWN ACTIF")
        logger.info(f"{'='*80}")
        logger.info(f"[COOLDOWN] ‚è±Ô∏è  Temps √©coul√©: {elapsed_since_last:.1f}s / {required_cooldown}s requis")
        logger.info(f"[COOLDOWN] üìä Score de pertinence: {relevance_score}/100")
        logger.info(f"[COOLDOWN] üö´ Raison: Cooldown adaptatif en cours")
        logger.info(f"{'='*80}\n")

        return {
            "advice": None,
            "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}",
            "reason": "cooldown_active",
            "cooldown_info": {
                "elapsed": round(elapsed_since_last, 1),
                "required": required_cooldown,
                "relevance_score": relevance_score
            }
        }

    # Si score trop faible, ne pas g√©n√©rer
    if not should_generate:
        logger.info(f"\n{'='*80}")
        logger.info(f"[PERTINENCE] üö´ INSIGHT NON G√âN√âR√â - SCORE TROP FAIBLE")
        logger.info(f"{'='*80}")
        logger.info(f"[PERTINENCE] üìä Score: {relevance_score}/100 (min requis: {MIN_RELEVANCE_SCORE})")
        logger.info(f"[PERTINENCE] üìù Analyse: {', '.join(analysis['reasons'])}")
        logger.info(f"[PERTINENCE] üí° Triggers: {', '.join(analysis['triggers']) if analysis['triggers'] else 'Aucun'}")
        logger.info(f"{'='*80}\n")

        return {
            "advice": None,
            "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}",
            "reason": "low_relevance",
            "relevance_info": {
                "score": relevance_score,
                "min_required": MIN_RELEVANCE_SCORE,
                "analysis": analysis
            }
        }

    # 3. Si on arrive ici : pertinence OK + cooldown OK ‚Üí G√©n√©rer l'insight
    logger.info(f"\n{'='*80}")
    logger.info(f"[PERTINENCE] ‚úÖ G√âN√âRATION D'INSIGHT AUTORIS√âE")
    logger.info(f"{'='*80}")
    logger.info(f"[PERTINENCE] üìä Score: {relevance_score}/100")
    logger.info(f"[PERTINENCE] ‚è±Ô∏è  Cooldown: {elapsed_since_last:.1f}s (requis: {required_cooldown}s)")
    logger.info(f"[PERTINENCE] üéØ Triggers: {', '.join(analysis['triggers'])}")
    logger.info(f"{'='*80}\n")

    # CONSTRUCTION DU CONTEXTE
    context_window = manager.get_context_window()
    context = "\n".join([
        f"{'COMMERCIAL' if msg['role'] == 'user' else 'CLIENT'}: {msg['content']}" 
        for msg in context_window
    ])
    
    # G√âN√âRATION DU COACHING
    prompt = coaching_service.build_coaching_prompt(context, manager)
    raw_advice = await coaching_service.generate_insight(prompt)
    
    if not raw_advice:
        return {
            "advice": None,
            "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}"
        }
    
    # PARSING
    advice_json = coaching_service.parse_insight_response(raw_advice)
    
    if not advice_json:
        return {
            "advice": None,
            "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}"
        }
    
    # V√âRIFICATION ANTI-DOUBLON AVEC IA (avec prise en compte du temps)
    full_insight = f"{advice_json['title']} - {advice_json['details']['description']}"
    
    logger.info(f"\n{'='*80}")
    logger.info(f"[ANTI-DOUBLON] üîç V√âRIFICATION DOUBLON EN COURS")
    logger.info(f"{'='*80}")
    logger.info(f"[INSIGHT] üìù NOUVEL INSIGHT G√âN√âR√â:")
    logger.info(f"[INSIGHT]    Type: {advice_json['type'].upper()}")
    logger.info(f"[INSIGHT]    Titre: {advice_json['title']}")
    logger.info(f"[INSIGHT]    Action: {advice_json['details']['description']}")
    logger.info(f"[INSIGHT]    Insight complet: {full_insight}")
    logger.info(f"{'='*80}")
    logger.info(f"[INSIGHT] ‚è±Ô∏è  Seuil temporel harmonis√©: {TIME_THRESHOLD_DUPLICATE}s (utilis√© partout)")
    logger.info(f"[INSIGHT] üß¨ V√©rification par vectorisation s√©mantique...")

    # üÜï Utiliser le seuil harmonis√© (30s par d√©faut)
    is_duplicate = await manager.is_duplicate_insight(full_insight, time_threshold_seconds=TIME_THRESHOLD_DUPLICATE)
    
    if is_duplicate:
        logger.info(f"\n{'='*80}")
        logger.info(f"[ANTI-DOUBLON] ‚ùå INSIGHT REJET√â - DOUBLON D√âTECT√â")
        logger.info(f"{'='*80}")
        logger.info(f"[INSIGHT] üö´ INSIGHT BLOQU√â:")
        logger.info(f"[INSIGHT]    Type: {advice_json['type'].upper()}")
        logger.info(f"[INSIGHT]    Titre: {advice_json['title']}")
        logger.info(f"[INSIGHT]    Action: {advice_json['details']['description']}")
        logger.info(f"[INSIGHT]    Insight complet: {full_insight}")
        logger.info(f"")
        logger.info(f"[INSIGHT] üìä HISTORIQUE DES INSIGHTS (pour comparaison):")
        for i, old_insight in enumerate(manager.last_insights[-5:], 1):
            logger.info(f"[INSIGHT]    {i}. {old_insight[:80]}...")
        logger.info(f"{'='*80}\n")
        
        return {
            "advice": None,
            "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}",
            "reason": "duplicate",
            "blocked_insight": {
                "type": advice_json['type'],
                "title": advice_json['title'],
                "description": advice_json['details']['description'],
                "full_text": full_insight
            }
        }
    
    # Ajouter au cache
    logger.info(f"\n{'='*80}")
    logger.info(f"[ANTI-DOUBLON] ‚úÖ INSIGHT VALID√â ET ACCEPT√â")
    logger.info(f"{'='*80}")
    logger.info(f"[INSIGHT] ‚ú® INSIGHT AJOUT√â AU CACHE:")
    logger.info(f"[INSIGHT]    Type: {advice_json['type'].upper()}")
    logger.info(f"[INSIGHT]    Titre: {advice_json['title']}")
    logger.info(f"[INSIGHT]    Action: {advice_json['details']['description']}")
    logger.info(f"{'='*80}\n")
    manager.add_insight(full_insight)
    
    return {
        "advice": advice_json,
        "transcription": f"CLIENT: {client_text}\nCOMMERCIAL: {commercial_text}",
        "conversation_phase": manager.conversation_phase
    }


