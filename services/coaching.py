"""
Service de gÃ©nÃ©ration d'insights et coaching en temps rÃ©el
"""
import logging
import asyncio
from typing import Optional, Dict
import openai

from config.settings import (
    FINE_TUNED_MODEL,
    COACHING_TEMPERATURE,
    PRODUCT_NAME,
    PRODUCT_DESCRIPTION,
    SALES_FRAMEWORK,
    COMPANY_INDUSTRY,
)

logger = logging.getLogger(__name__)


class CoachingService:
    """Service de gÃ©nÃ©ration d'insights de coaching"""
    
    def __init__(self):
        self.model = FINE_TUNED_MODEL
        self.temperature = COACHING_TEMPERATURE
    
    async def generate_insight(self, prompt: str) -> Optional[str]:
        """
        GÃ©nÃ¨re un insight de coaching via le modÃ¨le fine-tunÃ©
        
        Args:
            prompt: Prompt complet avec contexte
        
        Returns:
            Texte brut de l'insight ou None
        """
        try:
            response = await asyncio.to_thread(
                openai.chat.completions.create,
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=80,  # âœ… OPTIMISÃ‰: 80 tokens pour format dataset complet
                temperature=self.temperature
            )
            
            raw_advice = response.choices[0].message.content.strip()
            logger.info(f"[IA] RÃ©ponse brute: {raw_advice}")
            
            return raw_advice
            
        except Exception as e:
            logger.error(f"[IA] Erreur lors de l'appel GPT: {e}")
            return None
    
    def build_coaching_prompt(self, context: str, manager) -> str:
        """
        âš¡ PROMPT SYSTÃˆME OPTIMISÃ‰ : 5 Piliers + Analyse IncrÃ©mentale (30 derniÃ¨res secondes)

        Architecture Performance:
        - Contexte rÃ©duit: 30 derniÃ¨res secondes max (au lieu de tout l'historique)
        - Prompt structurÃ©: 5 piliers explicites pour guidance IA
        - Format court forcÃ©: Max 15 mots pour lecture instantanÃ©e
        """

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. ANALYSE INCRÃ‰MENTALE : 30 DERNIÃˆRES SECONDES UNIQUEMENT
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Approximation: 1 message â‰ˆ 5-10 secondes de conversation
        # â†’ Prendre max 5 derniers messages (â‰ˆ 30 secondes de contexte)
        recent_messages = manager.messages[-5:] if len(manager.messages) >= 5 else manager.messages

        phase_labels = {
            "introduction": "Intro",
            "discovery": "Discovery",
            "presentation": "Pitch",
            "negotiation": "NÃ©go",
            "closing": "Closing"
        }
        phase = phase_labels.get(manager.conversation_phase, manager.conversation_phase)

        # âœ… FORMAT EXACT DU DATASET: emoji + "Pilier X - Nom"
        pillar_icons = {
            "not_started": "âšª",
            "in_progress": "ðŸŸ¡",
            "completed": "ðŸŸ¢"
        }

        # Mapping des noms pour matcher EXACTEMENT le dataset
        pillar_names_dataset = {
            1: "Comprendre le contexte",
            2: "Identifier le problÃ¨me",  # Sans "vrai"
            3: "Mesurer l'impact",
            4: "Valider le dÃ©cisionnel",
            5: "Next Step"  # Sans "intelligent"
        }

        pillar_summary = "\n".join([
            f"{pillar_icons[p['status']]} Pilier {i} - {pillar_names_dataset[i]}"
            for i, p in manager.pillar_progress.items()
        ])

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. FORMATAGE DES MESSAGES (5 derniers = ~30 secondes)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Utiliser recent_messages dÃ©fini plus haut (5 derniers messages)
        formatted_messages = "\n".join([
            f"{'CLIENT' if msg['role'] == 'assistant' else 'COMMERCIAL'}: {msg['content']}"
            for msg in recent_messages
        ])

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 3. PROMPT SYSTÃˆME OPTIMISÃ‰ : Les 5 Piliers explicites
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt = f"""**MÃ‰THODOLOGIE - 5 PILIERS DE DISCOVERY B2B** :
1ï¸âƒ£ Comprendre le contexte : Questions sur situation actuelle AVANT de pitcher
2ï¸âƒ£ Identifier le problÃ¨me : Creuser les pains profonds et quantifiables
3ï¸âƒ£ Mesurer l'impact : Quantifier en temps, argent, risques
4ï¸âƒ£ Valider le dÃ©cisionnel : Qui dÃ©cide, budget, timeline (MEDDIC)
5ï¸âƒ£ Next Step : Proposer suite concrÃ¨te (dÃ©mo, pilot)

**DERNIERS Ã‰CHANGES (30 derniÃ¨res secondes)** :
{formatted_messages}

**PROGRESSION DES PILIERS** :
{pillar_summary}

Que recommandes-tu ?

RÃ©ponds en 1 ligne courte (max 15 mots) au format : [titre simple] - [action simple]"""

        return prompt
    
    def parse_insight_response(self, raw_response: str) -> Optional[Dict]:
        """
        Parse la rÃ©ponse du modÃ¨le au format SIMPLE: titre - action

        âœ… FORMAT ATTENDU: [titre simple] - [action simple]
        âœ… ACCEPTE avec ou sans emojis, avec ou sans prÃ©fixes
        """

        response = raw_response.strip()

        # VÃ©rifier si vide
        if not response or len(response) < 5:
            logger.warning("[PARSING] âŒ RÃ©ponse vide ou trop courte")
            return None

        # Nettoyer les emojis et prÃ©fixes communs (optionnels)
        emoji_to_type = {
            "ðŸŸ¢": "progression",
            "ðŸ”µ": "opportunity",
            "ðŸ”´": "alert"
        }

        detected_type = "progression"  # Type par dÃ©faut

        # DÃ©tecter l'emoji si prÃ©sent (optionnel)
        for emoji, type_name in emoji_to_type.items():
            if emoji in response:
                detected_type = type_name
                response = response.replace(emoji, "").strip()
                break

        # Retirer prÃ©fixes communs si prÃ©sents (optionnel)
        prefixes = ["Signal de progression", "Signal d'opportunitÃ©", "Signal d'alerte",
                   "Progression", "OpportunitÃ©", "Alerte"]
        for prefix in prefixes:
            if response.startswith(prefix):
                response = response[len(prefix):].strip()
                # Retirer : ou | au dÃ©but
                if response.startswith(":") or response.startswith("|"):
                    response = response[1:].strip()
                break

        # PARSER "Titre - Action" (seule contrainte obligatoire)
        if " - " not in response:
            logger.warning(f"[PARSING] âŒ SÃ©parateur ' - ' manquant: {raw_response}")
            return None

        parts = response.split(" - ", 1)
        title = parts[0].strip()
        action = parts[1].strip()

        # Validation minimale (juste Ã©viter les cas absurdes)
        if len(title) < 3:
            title = "Signal dÃ©tectÃ©"
        if len(action) < 3:
            action = "Analyser la situation"

        # Limiter les longueurs max
        if len(title) > 100:
            title = title[:97] + "..."
        if len(action) > 150:
            action = action[:147] + "..."

        # CONSTRUIRE L'INSIGHT
        insight = {
            "title": title,
            "type": detected_type,
            "details": {
                "description": action
            }
        }

        logger.info(f"[PARSING] âœ… Format simple: {title} - {action}")

        return insight
